{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a PyTorch Classification Model with Azure ML and AML Compute\n",
    "\n",
    "Here we have a driver notebook that uses Azure ML Python SDK to create a Datastore (object linking to data in Blob), AmlCompute (compute cluster for training) and a PyTorch estimator to tell Azure ML where to find the training script and how to train.\n",
    "\n",
    "Note:\n",
    "* Please use the \"Python 3.6 - PyTorch 1.1\" kernel for this notebook or install appropriate library versions below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure specific Azure ML Python SDK version install\n",
    "import sys\n",
    "! {sys.prefix}/bin/pip install --upgrade azureml-sdk==1.0.83\n",
    "! {sys.prefix}/bin/pip install matplotlib\n",
    "\n",
    "## If running locally and need to install PyTorch:\n",
    "# ! {sys.prefix}/bin/pip install --upgrade torch==1.1 torchvision==0.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.authentication import ServicePrincipalAuthentication\n",
    "from azureml.core import Workspace, Experiment, Datastore\n",
    "from azureml.exceptions import ProjectSystemException\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.train.dnn import PyTorch\n",
    "import shutil\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "# User will set the following\n",
    "my_nickname = ...\n",
    "\n",
    "STORAGE_CONTAINER_NAME_TRAINDATA=\n",
    "STORAGE_ACCOUNT_NAME=\n",
    "STORAGE_ACCOUNT_KEY="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core\n",
    "import torch\n",
    "\n",
    "print(\"SDK version: \", azureml.core.VERSION)\n",
    "print(\"PyTorch version: \", torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnostics\n",
    "Opt-in diagnostics for better experience, quality, and security of future releases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.telemetry import set_diagnostics_collection\n",
    "\n",
    "set_diagnostics_collection(send_diagnostics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize workspace\n",
    "Initialize a [Workspace](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#workspace) object from the existing workspace you created in the Prerequisites. `Workspace.from_config()` creates a workspace object from the details stored in `config.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "\n",
    "ws = Workspace.from_config(path='config.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create or Attach existing AmlCompute\n",
    "You will need to create a [compute target](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#compute-target) for training your model. In this tutorial, we use Azure ML managed compute ([AmlCompute](https://docs.microsoft.com/azure/machine-learning/service/how-to-set-up-training-targets#amlcompute)) for our remote training compute resource.\n",
    "\n",
    "**Creation of AmlCompute takes approximately 5 minutes.** If the AmlCompute with that name is already in your workspace, this code will skip the creation process.\n",
    "\n",
    "As with other Azure services, there are limits on certain resources (e.g. AmlCompute) associated with the Azure Machine Learning service. Please read [this article](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-manage-quotas) on the default limits and how to request more quota."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a name for your cluster - under 16 characters\n",
    "cluster_name = \"gpuforpytorch\"\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing compute target.')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    # AML Compute config - if max_nodes are set, it becomes persistent storage that scales\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_NC6',\n",
    "                                                        min_nodes=0,\n",
    "                                                        max_nodes=3)\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "    compute_target.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the provisioning status of the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use get_status() to get a detailed status for the current cluster. \n",
    "print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a project directory and copy training script to it\n",
    "project_folder = os.path.join(os.getcwd(), 'project')\n",
    "os.makedirs(project_folder, exist_ok=True)\n",
    "shutil.copy(os.path.join(os.getcwd(), 'pytorch_train_transfer.py'), project_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an experiment\n",
    "\n",
    "Create an [Experiment](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#experiment) to track all the runs in your workspace for this transfer learning PyTorch tutorial.\n",
    "\n",
    "Think of an experiment like a scenario such as \"finding images of people fighting in CCTV feeds\".  An experiment usually will have many \"runs\" which could entail updates to the data, hyperparameters, training code itself, and other optimizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an experiment\n",
    "experiment_name = 'suspicious-behavior-' + my_nickname\n",
    "experiment = Experiment(ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use an Azure Blob Container as Datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use an Azure ML Data Store for training data\n",
    "ds = Datastore.register_azure_blob_container(workspace=ws, \n",
    "    datastore_name='defaultdatastore', \n",
    "    container_name=STORAGE_CONTAINER_NAME_TRAINDATA,\n",
    "    account_name=STORAGE_ACCOUNT_NAME, \n",
    "    account_key=STORAGE_ACCOUNT_KEY,\n",
    "    create_if_not_exists=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "To train the PyTorch model we are going to use a Azure ML Estimator specific to PyTorch - see [Train models with Azure Machine Learning using estimator](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-train-ml-models) for more on Estimators.  We will use the Datastore we specified earlier which mounts the Blob Storage container to the remote compute target for training in this case.\n",
    "\n",
    "To learn more about where read and write files in a local or remote compute see [Where to save and write files for Azure Machine Learning experiments](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-save-write-experiment-files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up for training (\"trans\" flag means - use transfer learning and \n",
    "# this should download a model on compute)\n",
    "# Using /tmp to store model and info due to the fact that\n",
    "# creating new folders and files on the Azure Function host\n",
    "# will trigger the function to restart.\n",
    "script_params = {\n",
    "    '--data_dir': ds.as_mount(),\n",
    "    '--num_epochs': 30,\n",
    "    '--learning_rate': 0.01,\n",
    "    '--output_dir': './outputs',\n",
    "    '--trans': 'True'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate PyTorch estimator with upload of final model to\n",
    "# a specified blob storage container (this can be anything)\n",
    "estimator = PyTorch(source_directory=project_folder, \n",
    "                    script_params=script_params,\n",
    "                    compute_target=compute_target,\n",
    "                    entry_script='pytorch_train_transfer.py',\n",
    "                    use_gpu=True,\n",
    "                    pip_packages=['matplotlib==3.1.1',\n",
    "                                  'opencv-python==4.1.1.26', \n",
    "                                  'Pillow==6.2.1'],\n",
    "                   framework_version='1.2')\n",
    "\n",
    "run = experiment.submit(estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check run status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(run.get_details())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register model to workspace\n",
    "\n",
    "This will allow accessibility to the model through the SDK in other runs or experiments.\n",
    "\n",
    "This code is found in the training script where access exists to the run object.\n",
    "\n",
    "```python\n",
    "model = run.register_model(model_name='pt-dnn', model_path='outputs/model_finetuned.pth')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Alternatively, register within this notebook \n",
    "# (the model_path is the Azure ML workspace model path, not local)\n",
    "\n",
    "## Get one particular Run using run id found in Azure Portal\n",
    "# from azureml.core import Run\n",
    "# run = Run(experiment, run_id='suspicious-behavior-...')\n",
    "\n",
    "# Register model to Models in workspace\n",
    "model = run.register_model(model_name='suspicious-behavior-pytorch', model_path='outputs/model_finetuned.pth',\n",
    "                          description='Squeezenet PyTorch model; 30 epochs; 0.01 LR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model\n",
    "\n",
    "You will need test images in the test_images folder in the following folder structure:\n",
    "\n",
    "```\n",
    "test_images\n",
    "    \\test\n",
    "        \\normal\n",
    "        \\suspicious\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from azureml.core.model import Model\n",
    "\n",
    "data_dir = '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model( ws, 'suspicious-behavior-pytorch', version=1).download(exist_ok=True)\n",
    "model = torch.load('model_finetuned.pth', map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, 'test_images', x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['test']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=1,\n",
    "                                              shuffle=False, num_workers=0)\n",
    "               for x in ['test']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['test']}\n",
    "class_names = image_datasets['test'].classes\n",
    "print(dataset_sizes['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peform inference on test data set to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over data.\n",
    "running_corrects = 0\n",
    "for inputs, labels in dataloaders['test']:\n",
    "\n",
    "    # Don't need to track history \n",
    "    with torch.set_grad_enabled(False):\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "    # Statistics\n",
    "    running_corrects += torch.sum(preds == labels.data)\n",
    "    \n",
    "overall_acc = running_corrects.double() / dataset_sizes['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy = ', overall_acc.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
