{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy a PyTorch Model as a Web Service Azure ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTANT:\n",
    "* Please use the **\"Python 3.6 - Azure ML\" kernel** on the DSVM for this notebook or install appropriate library versions below (to change a kernel go to Kernel in the menu bar and select \"Change kernel\").\n",
    "* You will need your `config.json` from your Azure ML Workspace in the **same folder** as this notebook and interactive login will be performed later on so be prepared with your Azure login info.  You may wish to work with these notebooks in an **Incognito or Private browser window** in case you have other Azure accounts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "from azureml.core.webservice import AciWebservice, LocalWebservice\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.environment import Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize workspace\n",
    "\n",
    "Initialize a [Workspace](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#workspace) object from the existing workspace you created in the Prerequisites. `Workspace.from_config()` creates a workspace object from the details stored in `config.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config(path='config.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide the experiment suffix used in the training notebook.  Replace `***`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_nickname = ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Deploy model as web service\n",
    "Once you have your trained model, you can deploy the model on Azure. In this tutorial, we will deploy the model as a web service in Azure Container Instances (ACI). For more information on deploying models using Azure ML, refer to [Deploy models with Azure Machine Learning](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-deploy-and-where).\n",
    "\n",
    "**Create scoring script**\n",
    "\n",
    "First, we will utilize a pre-made scoring script that will be invoked by the web service call. Note that the scoring script must have two required functions (take a look at `pytorch_score.py`, now):\n",
    "\n",
    "1. `init()`: In this function, you typically load the model into a global object. This function is executed only once when the Docker container is started.\n",
    "\n",
    "\n",
    "2. `run(input_data)`:  In this function, the model is used to predict a value based on the input data. The input and output typically use JSON as serialization and deserialization format, but you are not limited to that.\n",
    "\n",
    "\n",
    "Refer to the scoring script `pytorch_score.py` for this tutorial. Our web service will use this file to predict on the new image that is sent as a REST call. When writing your own scoring script, don't forget to test it locally first before you go and deploy the web service.  This will make debugging easier.\n",
    "\n",
    "**Create environment file**\n",
    "\n",
    "As part of deploying, we need more than our Python scoring script.  The service is based on a docker image that encapsulates the entire set of requirements.  We will need to create an environment file (`myenv.yml`) that specifies all of the scoring script's package dependencies. This file is used to ensure that all of those dependencies are installed in the Docker image by Azure ML. In this case, we need to specify `azureml-core`, `torch` and `torchvision`.  Let's make sure to be consistent in versions.\n",
    "\n",
    "Beyond `conda` dependencies, we can also specify `pip` installable dependencies (not shown here)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create environment file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myenv = CondaDependencies.create(pip_packages=['azureml-defaults==1.5.0', \n",
    "                                               'torch==1.3.0', \n",
    "                                               'torchvision==0.4.1',\n",
    "                                               'Pillow==6.2.1'])\n",
    "\n",
    "with open(\"myenv.yml\",\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())\n",
    "    \n",
    "print(myenv.serialize_to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get registered model\n",
    "\n",
    "Note, you can update the `version` to match the latest one you wish to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(ws,'behavior-pytorch-'+my_nickname, version=1)#.download(exist_ok=True)\n",
    "print(model.name, model.id, model.version, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up environment\n",
    "\n",
    "A good reference notebook from Azure ML team on environments can be found here:  https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/training/using-environments/using-environments.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myenv = Environment.from_conda_specification(name='myenv',\n",
    "                                             file_path='myenv.yml')\n",
    "\n",
    "\n",
    "myenv.environment_variables = {'MODEL_NAME': 'behavior-pytorch-'+my_nickname,\n",
    "                               'VERSION': 1}\n",
    "myenv.register(workspace=ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up inference config\n",
    "\n",
    "Create an inference configuration which gives specifies the inferencing environment and scripts.  This will be used in the local deployment as well as the deployment to ACI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_config = InferenceConfig(entry_script=\"pytorch_score.py\",\n",
    "                                   environment=myenv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy locally to test - may take some time\n",
    "\n",
    "Always a good idea.\n",
    "\n",
    "IMPORTANT:  You will need to be able to run `docker` without `sudo` on the machine where you run this notebook.  If you get a \"Permission denied\" error please follow the guidance (https://docs.docker.com/engine/install/linux-postinstall/#manage-docker-as-a-non-root-user) to create a docker group and add the user, then restart the JupyterHub server (check out the Control Panel).\n",
    "\n",
    "Building the docker image for the first time may take ~15 minutes depending upon your compute resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set up deployment configuration\n",
    "deployment_config = LocalWebservice.deploy_configuration(port=6789)\n",
    "\n",
    "# Create service\n",
    "local_service = Model.deploy(ws, 'test', [model], inference_config, deployment_config)\n",
    "local_service.wait_for_deployment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_service.get_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send a test image to the local service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "input_data = Image.open('test_images/Fight_OneManDown321.jpg')\n",
    "input_data = np.asarray(input_data)\n",
    "result = local_service.run(input_data=json.dumps({'data': input_data.tolist()}))\n",
    "print(result)\n",
    "\n",
    "\n",
    "input_data = Image.open('test_images/Browse10986.jpg')\n",
    "input_data = np.asarray(input_data)\n",
    "result = local_service.run(input_data=json.dumps({'data': input_data.tolist()}))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy to ACI container\n",
    "We are ready to deploy. Create a deployment configuration file to specify the number of CPUs and gigabytes of RAM needed for your ACI container. While it depends on your model, the default of 1 core and 3 gigabyte of RAM is usually sufficient for many models. This cell will run for about 5-20 minutes.\n",
    "\n",
    "Note:  service names must be unique.  Delete service or rename if you wish to deploy another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "myenv = Environment.from_conda_specification(name='myenv',\n",
    "                                             file_path='myenv.yml')\n",
    "\n",
    "# Clear out vars for the ACI version of deployment\n",
    "myenv.environment_variables = {'MODEL_NAME': '',\n",
    "                               'VERSION': ''}\n",
    "myenv.register(workspace=ws)\n",
    "\n",
    "# Recreate inference config since we changed the environment\n",
    "inference_config = InferenceConfig(entry_script=\"pytorch_score.py\",\n",
    "                                   environment=myenv)\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n",
    "                                               memory_gb=3, \n",
    "                                               tags={'data': 'suspicious-behavior',  \n",
    "                                                     'method':'transfer learning', \n",
    "                                                     'framework':'pytorch'},\n",
    "                                               description='Classify normal/suspicious behavior in PyTorch')\n",
    "\n",
    "service = Model.deploy(workspace=ws, \n",
    "                           name='aci-suspicious-behavior-1', \n",
    "                           models=[model],\n",
    "                           inference_config=inference_config, \n",
    "                           deployment_config=aciconfig)\n",
    "service.wait_for_deployment(True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your deployment fails for any reason and you need to redeploy, make sure to delete the service before you do so: `service.delete()` - see \"Clean up\" section below.\n",
    "\n",
    "**Tip**: If something goes wrong with the deployment, the first thing to look at is the logs from the service by running the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.get_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the web service's HTTP endpoint, which accepts REST client calls. This endpoint can be shared with anyone who wants to test the web service or integrate it into an application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.scoring_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the web service\n",
    "Finally, let's test our deployed web service. We will send the data as a JSON string to the web service hosted in ACI and use the SDK's run API to invoke the service. Here we will take an image from our validation data to predict on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.imshow(Image.open('test_images/Fight_OneManDown321.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "input_data = Image.open('test_images/Fight_OneManDown321.jpg')\n",
    "input_data = np.asarray(input_data)\n",
    "result = service.run(input_data=json.dumps({'data': input_data.tolist()}))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "1. Use the packaging models functionality of Azure ML to package the model as set of prerequisite files to inspect and build custom docker image.\n",
    "2. Build the image from this notebook or from Terminal.\n",
    "3. Run the container from this notebook or from Terminal.\n",
    "4. (BONUS) Test the local container using the `requests` library as shown in the documentation.\n",
    "\n",
    "\n",
    "\n",
    "See [Generate a Dockerfile and dependencies](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-and-where#generate-a-dockerfile-and-dependencies)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "Once you no longer need the web service, you can delete it with a simple API call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update service\n",
    "\n",
    "To update the service with the SDK, a good guide can be found in the docs:  https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-azure-container-instance#update-the-web-service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
